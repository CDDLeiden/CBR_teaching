{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This lab is in part adapted from TeachOpenCADD\n",
    "(https://github.com/volkamerlab/teachopencadd/tree/master/teachopencadd/talktorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load some libraries again first\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, recall_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, AllChem\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#from teachopencadd.utils import seed_everything\n",
    "\n",
    "# Silence some expected warnings\n",
    "filterwarnings(\"ignore\")\n",
    "# Fix seed for reproducible results\n",
    "SEED = 22\n",
    "#seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will look into cheminformatics. We ended the last session looking at the interaction of the ligand in the binding site. To refresh our minds, \n",
    "\n",
    "1. lets have another look at the protein-ligand interactions with PLIP:\n",
    "\n",
    " https://plip-tool.biotec.tu-dresden.de/plip-web/plip/index\n",
    " \n",
    " What also is informative is to do a short literature study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find the Structure – Activity – Relationship (SAR) for your ligand. Use medicinal chemistry journals, like (but not limited to) J. Med. Chem., Bioorg Med Chem (Lett), ChemMedChem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. First, let's create a new working directory in your jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMEDIR = str(Path(_dh[0]))\n",
    "os.chdir(HOMEDIR)\n",
    "# We need to check whether the directory is there\n",
    "try:\n",
    "    os.mkdir('Cheminformatics')\n",
    "except:\n",
    "    print(\"Directory already exists\")\n",
    "os.chdir('Cheminformatics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, we need to have the SMILES (https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) representation of the molecule. You can retrieve this by going to the pdb, and fetch the InChI key for the ligand in your structure (use the RCSB accession code).\n",
    "\n",
    "4. The image below shows the InChI key for zma241385 in blue:\n",
    "\n",
    "![image info](img/LAB01_FIG00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the InChI key, you can retrieve the SMILES from PubChem ((http://pubchem.ncbi.nlm.nih.gov/). Use the search bar where you paste the InChI key in, then run the search, you should retrieve the compound. Click on the entry, and you can find them under 2.1.4 Canonical Smiles. Write down the SMILES that you retrieved from PUBCHEM\n",
    "\n",
    "\n",
    "6.\tFind similar compounds by going to the Similarity tab, how many compounds were retrieved? Under settings, you can adjust the tanimoto threshold, change it to 80%, how much are retrieved now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tGo to https://www.ebi.ac.uk/chembl/, again use the InChI key from the previous step, click the entry. Write down the CHEMBLID. Next, do a Structure Search (button under the compound drawing).\n",
    "\n",
    "8.\tFetch 95% similar compounds, how much compounds were retrieved? Do the same but with 90%. Do you have more or less compounds than in step 6? Do you know why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tUse the Zinc site to search for possible similar ligands at http://zinc15.docking.org/substances/home/ .Again use the copied smiles string do a 70 % similar search (Tanimoto 70, written as similarity -30). Write down the number of hits and copy 1 representative molecule from each search. Discuss the results, how high is the impact of the similarity threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining and cleaning data.\n",
    "\n",
    "Let's now start with some data. You should have a CHEMBLID in your list, here we use CHEMBL251 (Adenosine A2a) as an example.\n",
    "\n",
    "10. We're going to download a dataset downloaded from ChEMBL, and read it into pandas, you can download the files from ChEMBL directly and upload them to the notebook environment (https://www.ebi.ac.uk/chembl/). Be sure to upload the extracted file (not the .zip file) and to give it a clear name so you can write it down in the below code block. \n",
    "\n",
    "\n",
    "Ask a TA if anything is unclear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMBLID = 'CHEMBL205' # Enter the CHEMBL ID of your target here\n",
    "FILENAME = 'CHEMBL205.tsv' # The filename of the uploaded file\n",
    "\n",
    "data = pd.read_csv(f'{HOMEDIR}/{FILENAME}', sep='\\t')\n",
    "\n",
    "print(f\"There are a total of {len(data)} datapoints in this set\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will note that we have a lot of data, and we certainly don't need it all, thus we're going to remove quite some columns.\n",
    "\n",
    "11. Actually, for now we only need the compound ID, pCHEMBL_value, Assay Type, binding affinity and the smiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = data[['Molecule ChEMBL ID','pChEMBL Value','Smiles','Assay Type', 'Standard Relation','Standard Value']]\n",
    "pd_data.rename(columns={'pChEMBL Value': 'pChEMBL_value', 'Assay Type':'Assay_Type'}, inplace=True)\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add an activity classifier, there is a lot of censored data in the set and these typically are compounds that only bind weakly! We still want to know about those non-binders though.\n",
    "\n",
    "Let's set our activity threshold at PChEMBL > 6.5 for the actives, if you want to know more details have a look at this paper: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0232-0\n",
    "\n",
    "12. Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Add column for activity\n",
    "pd_data[\"active\"] = np.zeros(len(pd_data))\n",
    "\n",
    "# Mark every molecule as active with an pCHEMBL of >= 6.5, 0 otherwise\n",
    "pd_data.loc[pd_data[pd_data.pChEMBL_value >= 6.5].index, \"active\"] = 1.0\n",
    "\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Number of active compounds:\", int(pd_data.active.sum()))\n",
    "print(\"Number of inactive compounds:\", len(pd_data) - int(pd_data.active.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will drop functional assay readout, this is data that we don't want to consider in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data.drop(pd_data[pd_data.Assay_Type != 'B'].index, inplace=True)\n",
    "\n",
    "print(f\"We have a total of {len(pd_data)} activity points left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecule encoding\n",
    "\n",
    "Now we define a function `smiles_to_fp` to generate fingerprints from SMILES.\n",
    "For now, we incorporated the choice between the following fingerprints:\n",
    "\n",
    "* maccs\n",
    "* morgan2 and morgan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
    "    \"\"\"\n",
    "    Encode a molecule from a SMILES string into a fingerprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        The SMILES string defining the molecule.\n",
    "\n",
    "    method : str\n",
    "        The type of fingerprint to use. Default is MACCS keys.\n",
    "\n",
    "    n_bits : int\n",
    "        The length of the fingerprint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        The fingerprint array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert smiles to RDKit mol object\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    if method == \"maccs\":\n",
    "        return list(MACCSkeys.GenMACCSKeys(mol))\n",
    "    if method == \"morgan2\":\n",
    "        fingerprinter = AllChem.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
    "        return list(fingerprinter.GetFingerprint(mol))\n",
    "    if method == \"morgan3\":\n",
    "        fingerprinter = AllChem.GetMorganGenerator(radius=3, fpSize=n_bits)\n",
    "        return list(fingerprinter.GetFingerprint(mol))\n",
    "    else:\n",
    "        # NBVAL_CHECK_OUTPUT\n",
    "        print(f\"Warning: Wrong method specified: {method}. Default will be used instead.\")\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_df = pd_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "# Add column for fingerprint\n",
    "compound_df[\"fp\"] = compound_df[\"Smiles\"].progress_apply(smiles_to_fp)\n",
    "compound_df.dropna(subset='fp', inplace=True)\n",
    "compound_df.head(3)\n",
    "# NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning (ML)\n",
    "\n",
    "In the following, we will try several ML approaches to classify our molecules. We will use:\n",
    "\n",
    "* Random Forest (RF)\n",
    "* Support Vector Machine (SVM) \n",
    "* Artificial Neural Network (ANN) \n",
    "\n",
    "Additionally, we will comment on the results.\n",
    "\n",
    "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over fitting and to assess the generalization ability of the model.\n",
    "\n",
    "We start by defining a function `model_training_and_validation` which fits a model on a random train-test split of the data and returns measures such as accuracy, sensitivity, specificity and AUC evaluated on the test set. We also plot the ROC curves using `plot_roc_curves_for_models`.\n",
    "\n",
    "We then define a function named `crossvalidation` which executes a cross validation procedure and prints the statistics of the results over the folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "Helper function to plot customized ROC curves. Code inspired by [stackoverflow](https://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves_for_models(models, test_x, test_y, save_png=True):\n",
    "    \"\"\"\n",
    "    Helper function to plot customized roc curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models: dict\n",
    "        Dictionary of pretrained machine learning models.\n",
    "    test_x: list\n",
    "        Molecular fingerprints for test set.\n",
    "    test_y: list\n",
    "        Associated activity labels for test set.\n",
    "    save_png: bool\n",
    "        Save image to disk (default = False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig:\n",
    "        Figure.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Below for loop iterates through your models list\n",
    "    for model in models:\n",
    "        # Select the model\n",
    "        ml_model = model[\"model\"]\n",
    "        # Prediction probability on test set\n",
    "        test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
    "        # Prediction class on test set\n",
    "        test_pred = ml_model.predict(test_x)\n",
    "        # Compute False postive rate and True positive rate\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_y, test_prob)\n",
    "        # Calculate Area under the curve to display on the plot\n",
    "        auc = roc_auc_score(test_y, test_prob)\n",
    "        # Plot the computed values\n",
    "        ax.plot(fpr, tpr, label=(f\"{model['label']} AUC area = {auc:.2f}\"))\n",
    "\n",
    "    # Custom settings for the plot\n",
    "    ax.plot([0, 1], [0, 1], \"r--\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"Receiver Operating Characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    # Save plot\n",
    "    if save_png:\n",
    "        fig.savefig(f\"results/roc_auc\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to calculate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(ml_model, test_x, test_y, verbose=True):\n",
    "    \"\"\"\n",
    "    Helper function to calculate model performance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    test_x: list\n",
    "        Molecular fingerprints for test set.\n",
    "    test_y: list\n",
    "        Associated activity labels for test set.\n",
    "    verbose: bool\n",
    "        Print performance measure (default = True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        Accuracy, sensitivity, specificity, auc on test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prediction probability on test set\n",
    "    test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    # Prediction class on test set\n",
    "    test_pred = ml_model.predict(test_x)\n",
    "\n",
    "    # Performance of model on test set\n",
    "    accuracy = accuracy_score(test_y, test_pred)\n",
    "    sens = recall_score(test_y, test_pred)\n",
    "    spec = recall_score(test_y, test_pred, pos_label=0)\n",
    "    auc = roc_auc_score(test_y, test_prob)\n",
    "    bal_accuracy = (sens + spec) / 2\n",
    "    mcc = matthews_corrcoef(test_y, test_pred)\n",
    "\n",
    "    if verbose:\n",
    "        # Print performance results\n",
    "        # NBVAL_CHECK_OUTPUT\n",
    "        print(f\"Accuracy: {accuracy:.2}\")\n",
    "        print(f\"Sensitivity: {sens:.2f}\")\n",
    "        print(f\"Specificity: {spec:.2f}\")\n",
    "        print(f\"AUC: {auc:.2f}\")\n",
    "        print(f\"Balanced accuracy: {bal_accuracy:.2f}\")\n",
    "        print(f'Matthews correlation coefficient: {mcc:.2f}')\n",
    "\n",
    "    return accuracy, sens, spec, auc, bal_accuracy, mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Helper function to fit a machine learning model on a random train-test split of the data and return the performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_validation(ml_model, name, splits, verbose=True):\n",
    "    \"\"\"\n",
    "    Fit a machine learning model on a random train-test split of the data\n",
    "    and return the performance measures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    name: str\n",
    "        Name of machine learning algorithm: RF, SVM, ANN\n",
    "    splits: list\n",
    "        List of desciptor and label data: train_x, test_x, train_y, test_y.\n",
    "    verbose: bool\n",
    "        Print performance info (default = True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        Accuracy, sensitivity, specificity, auc on test set.\n",
    "\n",
    "    \"\"\"\n",
    "    train_x, test_x, train_y, test_y = splits\n",
    "\n",
    "    # Fit the model\n",
    "    ml_model.fit(train_x, train_y)\n",
    "\n",
    "    # Calculate model performance results\n",
    "    accuracy, sens, spec, auc, bal_accuracy, mcc = model_performance(ml_model, test_x, test_y, verbose)\n",
    "\n",
    "    return accuracy, sens, spec, auc, bal_accuracy, mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**: Split the data (will be reused for the other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_to_model = np.array(compound_df.fp.tolist())\n",
    "label_to_model = compound_df.active.tolist()\n",
    "\n",
    "# Split data randomly in train and test set\n",
    "# note that we use test/train_x for the respective fingerprint splits\n",
    "# and test/train_y for the respective label splits\n",
    "(\n",
    "    static_train_x,\n",
    "    static_test_x,\n",
    "    static_train_y,\n",
    "    static_test_y,\n",
    ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=12)\n",
    "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Training data size:\", len(static_train_x))\n",
    "print(\"Test data size:\", len(static_test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest classifier\n",
    "\n",
    "We start with a random forest classifier, where we first set the parameters.\n",
    "For more information, see [sklearn Rand Forest models](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on a random train-test split and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameter for random forest\n",
    "param = {\n",
    "    \"n_estimators\": 100,  # number of trees to grows\n",
    "    \"criterion\": \"entropy\",  # cost function to be optimized for a split\n",
    "}\n",
    "model_RF = RandomForestClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_RF, \"RF\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list that stores all models. First one is RF.\n",
    "models = [{\"label\": \"Model_RF\", \"model\": model_RF}]\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except:\n",
    "    print(\"Directory already exists, continuing\")\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y)\n",
    "result_img = f'{os.getcwd()}/results/roc_auc.png'\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector classifier\n",
    "Here we train a SVM with a radial-basis function kernel (also: squared-exponential kernel). \n",
    "For more information, see [sklearn RBF kernel](http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model\n",
    "model_SVM = svm.SVC(kernel=\"rbf\", C=1, gamma=0.1, probability=True)\n",
    "\n",
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_SVM, \"SVM\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Append SVM model\n",
    "models.append({\"label\": \"Model_SVM\", \"model\": model_SVM})\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y)\n",
    "result_img = f'{os.getcwd()}/results/roc_auc.png'\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network classifier\n",
    "The last approach we try here is a neural network model. We train an MLPClassifier (Multi-layer Perceptron classifier) with 3 layers, each with 5 neurons. As before, we do the crossvalidation procedure and plot the results. For more information on MLP, see [sklearn MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model\n",
    "model_ANN = MLPClassifier(hidden_layer_sizes=(5, 3), random_state=12)\n",
    "\n",
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_ANN, \"ANN\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append ANN model\n",
    "models.append({\"label\": \"Model_ANN\", \"model\": model_ANN})\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y, True)\n",
    "result_img = f'{os.getcwd()}/results/roc_auc.png'\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models show very good values for all measured values (see AUCs) and thus seem to be predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Next, we will perform cross-validation experiments with the three different models.\n",
    "Therefore, we define a helper function for machine learning model training and validation in a cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(ml_model, df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    acc_per_fold = []\n",
    "    sens_per_fold = []\n",
    "    spec_per_fold = []\n",
    "    auc_per_fold = []\n",
    "    bal_acc_per_fold = []\n",
    "    mcc_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = df.iloc[train_index].fp.tolist()\n",
    "        train_y = df.iloc[train_index].active.tolist()\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = df.iloc[test_index].fp.tolist()\n",
    "        test_y = df.iloc[test_index].active.tolist()\n",
    "\n",
    "        # Performance for each fold\n",
    "        accuracy, sens, spec, auc, bal_accuracy, mcc = model_performance(fold_model, test_x, test_y, verbose)\n",
    "\n",
    "        # Save results\n",
    "        acc_per_fold.append(accuracy)\n",
    "        sens_per_fold.append(sens)\n",
    "        spec_per_fold.append(spec)\n",
    "        auc_per_fold.append(auc)\n",
    "        bal_acc_per_fold.append(bal_accuracy)\n",
    "        mcc_per_fold.append(mcc)\n",
    "\n",
    "    # Print statistics of results\n",
    "    print(\n",
    "        f\"Mean accuracy: {np.mean(acc_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(acc_per_fold):.2f} \\n\"\n",
    "        f\"Mean sensitivity: {np.mean(sens_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(sens_per_fold):.2f} \\n\"\n",
    "        f\"Mean specificity: {np.mean(spec_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(spec_per_fold):.2f} \\n\"\n",
    "        f\"Mean AUC: {np.mean(auc_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(auc_per_fold):.2f} \\n\"\n",
    "        f\"Mean Balanced accuracy: {np.mean(bal_acc_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(bal_acc_per_fold):.2f} \\n\"\n",
    "        f\"Mean Matthews correlation coefficient: {np.mean(mcc_per_fold):.2f} \\t\"\n",
    "        f\"and std: {np.std(mcc_per_fold):.2f} \\n\"        \n",
    "        f\"Time taken: {time.time() - t0:.2f}s\\n\"\n",
    "    )\n",
    "\n",
    "    return acc_per_fold, sens_per_fold, spec_per_fold, auc_per_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation**\n",
    "\n",
    "We now apply cross-validation and show the statistics for all three ML models. In real world conditions, cross-validation usually applies 5 or more folds, but for the sake of performance we will reduce it to 3. You can change the value of `N_FOLDS` in this cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: Next cell takes long to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(\"\\n======= \")\n",
    "    print(f\"{model['label']}\")\n",
    "    crossvalidation(model[\"model\"], compound_df, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the cross-validation performance for molecules encoded using Morgan fingerprint and not MACCS keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset data frame\n",
    "compound_df = compound_df.drop(['fp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "# Use Morgan fingerprint with radius 3\n",
    "compound_df[\"fp\"] = compound_df[\"Smiles\"].progress_apply(smiles_to_fp, args=(\"morgan3\",))\n",
    "compound_df.head(3)\n",
    "# NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: Next cell takes long to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    if model[\"label\"] == \"Model_SVM\":\n",
    "        # SVM is super slow with long fingerprints\n",
    "        # and will have a performance similar to RF\n",
    "        # We can skip it in this test, but if you want\n",
    "        # to run it, feel free to replace `continue` with `pass`\n",
    "        continue\n",
    "    print(\"\\n=======\")\n",
    "    print(model[\"label\"])\n",
    "    reduced_df = compound_df[['active','fp']]\n",
    "    crossvalidation(model[\"model\"], reduced_df, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been running classification models (is the compound going to be active or not, indicated by the active column we added in the dataframe). The next step is to see if we can also train a classification model. We will remove the censored data (the ones with no pChEMBL value), and train another model. \n",
    "\n",
    "Make a new function that works with regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation_reg(ml_model, df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    MAE_per_fold = []\n",
    "    RMSE_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in tqdm(kf.split(df), total=n_folds):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = df.iloc[train_index].fp.tolist()\n",
    "        train_y = df.iloc[train_index].pChEMBL_value.tolist()\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = df.iloc[test_index].fp.tolist()\n",
    "        test_y = df.iloc[test_index].pChEMBL_value.tolist()\n",
    "        \n",
    "        test_results = fold_model.predict(test_x)\n",
    "        # Prediction probability on test set\n",
    "        from sklearn import metrics\n",
    "\n",
    "        MAE_per_fold.append(metrics.mean_absolute_error(test_y, test_results))\n",
    "        #print('Mean Squared Error (MSE):', metrics.mean_squared_error(test_y, test_results))\n",
    "        RMSE_per_fold.append(np.sqrt(metrics.mean_squared_error(test_y, test_results)))\n",
    "        #mape = np.mean(np.abs((gt - pred) / np.abs(gt)))\n",
    "        #print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
    "        #print('Accuracy:', round(100*(1 - mape), 2))\n",
    "    return(MAE_per_fold,RMSE_per_fold,fold_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make new data and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_to_model = compound_df.fp.tolist()\n",
    "label_to_model = compound_df.pChEMBL_value.tolist()\n",
    "\n",
    "# Split data randomly in train and test set\n",
    "# note that we use test/train_x for the respective fingerprint splits\n",
    "# and test/train_y for the respective label splits\n",
    "(\n",
    "    static_train_x,\n",
    "    static_test_x,\n",
    "    static_train_y,\n",
    "    static_test_y,\n",
    ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=12)\n",
    "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Training data size:\", len(static_train_x))\n",
    "print(\"Test data size:\", len(static_test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The next cell takes a while!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick out NaN in the pChEMBL values\n",
    "compound_df_noNaN = compound_df.dropna()\n",
    "\n",
    "#Train model with RandomForestRegressor\n",
    "regressor = RandomForestRegressor()\n",
    "MAE, RMSE, trained_model = crossvalidation_reg(regressor , compound_df_noNaN, n_folds=N_FOLDS)\n",
    "\n",
    "print(\n",
    "f\"MAE: {np.mean(MAE):.2f} \\t\"\n",
    "f\"and std : {np.std(MAE):.2f} \\n\"\n",
    "f\"RMSE: {np.mean(RMSE):.2f} \\t\"\n",
    "f\"and std : {np.std(RMSE):.2f} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that we report different measures of accuracy. We no longer deal with categorical data so we now look at the errors between experimental data and predicted data using the MAE and RMSE. Typically, an MAE below 0.6 and/or RMSE below, approximately, is considered quite decent.\n",
    "\n",
    "Next, let's use the RF model to run predictions on a new compound. You can design your compounds in a sketcher (https://www.schrodinger.com/platform/products/schrodinger-2d-sketcher/) or an online tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first entry is the co-crystalized ligand \n",
    "# which is added for reference (so we can compare \n",
    "# to its actual pChEMBL value)\n",
    "# BELOW: add your own molecules\n",
    "test_smiles = [\n",
    "    \n",
    "    'C1=COC(=C1)C2=NN3C(=NC(=NC3=N2)NCCC4=CC=C(C=C4)O)N', # ZMA241385\n",
    "    'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'                        # Caffeine\n",
    "]\n",
    "\n",
    "fps = [smiles_to_fp(smiles,'morgan3') for smiles in tqdm(test_smiles)]\n",
    "\n",
    "predictions = trained_model.predict(fps)\n",
    "print(\"SMILES, PREDICTION\")\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{test_smiles[i]}, {prediction:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can paste a smiles string of a designed molecule in here yourself. It's probably a good idea to start close to molecules that are already in the training set (check ChEMBL for inspiration). Of course you can also go crazy and design what you like, but bear in mind that Machine Learning has that pesky applicability domain so the results you obtain might not be that accurate.\n",
    "\n",
    "You can generate SMILES strings for instance using the drawing function in molview (https://molview.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Discussion\n",
    "\n",
    "* Which model performed best on our data set and why?\n",
    "    * All three models perform (very) well on our dataset. The best models are the random forest and support vector machine models which showed a mean AUC of about 90%. Our neural network showed slightly lower results. \n",
    "    * There might be several reasons that random forest and support vector machine models performed best. Our dataset might be easily separable in active/inactive with some simple tree-like decisions or with the radial basis function, respectively. Thus, there is not such a complex pattern in the fingerprints to do this classification.\n",
    "    * A cause for the slightly poorer performance of the ANN could be that there was simply too few data to train the model on.\n",
    "    * Additionally, it is always advisable to have another external validation set for model evaluation.  \n",
    "* Was MACCS the right choice?\n",
    "    * Obviously, MACCS was good to start training and validating models to see if a classification is possible. \n",
    "    * However, MACCS keys are rather short (166 bit) compared to others (2048 bit), as for example Morgan fingerprint. As shown in the last simulation, having longer fingerprint helps the learning process. All tested models performed slightly better using Morgan fingerprints (see mean AUC increase).\n",
    "\n",
    "    \n",
    "### Where can we go from here?\n",
    "\n",
    "* We successfully trained several models. \n",
    "* The next step could be to use these models to do a classification with an unknown screening dataset to predict novel potential EGFR inhibitors.\n",
    "* An example for a large screening data set is e.g. [MolPort](https://www.molport.com/shop/database-download) with over 7 million compounds.\n",
    "* Our models could be used to rank the MolPort compounds and then further study those with the highest predicted probability of being active.\n",
    "* For such an application, see also the [TDT Tutorial](https://github.com/sriniker/TDT-tutorial-2014) developed by S. Riniker and G. Landrum, where they trained a fusion model to screen [eMolecules](https://www.emolecules.com/) for new anti-malaria drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "* How can you apply ML for virtual screening?\n",
    "* Which machine learning algorithms do you know?\n",
    "* What are necessary prerequisites to successfully apply ML?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
